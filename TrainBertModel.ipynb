{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNPCH1NlvNy3KIeXiMLrE0Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b639c6cc109d417b818f222e3edad8e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f1cd87081da40e5906c4271040a516e","IPY_MODEL_471ad496a0654901a757836c4449b55e","IPY_MODEL_39fb9f82cc974d7a8a6581db06c7df64"],"layout":"IPY_MODEL_7b038f8dbe52460b900b25a84714fdf0"}},"2f1cd87081da40e5906c4271040a516e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2970f890a6a849f5a6654254aff28476","placeholder":"​","style":"IPY_MODEL_43aea3a735624ef3ab9914ec68aad219","value":"model.safetensors: 100%"}},"471ad496a0654901a757836c4449b55e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_916115ac1ade44658cf6c50b6df4112a","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_197119cc1f864a89bb170d465b86df32","value":440449768}},"39fb9f82cc974d7a8a6581db06c7df64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_501572c52e83428cb3a0f939e5dc9825","placeholder":"​","style":"IPY_MODEL_799ba14b588349b9ac63ccfe40c9a957","value":" 440M/440M [00:03&lt;00:00, 149MB/s]"}},"7b038f8dbe52460b900b25a84714fdf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2970f890a6a849f5a6654254aff28476":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43aea3a735624ef3ab9914ec68aad219":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"916115ac1ade44658cf6c50b6df4112a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"197119cc1f864a89bb170d465b86df32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"501572c52e83428cb3a0f939e5dc9825":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"799ba14b588349b9ac63ccfe40c9a957":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Connect to Drive for Colab Execution\n","from google.colab import drive\n","import os\n","\n","\n","drive.mount('/content/gdrive/', force_remount=True)\n","\n","# get to correct Directory\n","%cd gdrive/MyDrive\n","os.chdir('./Adv_ML')\n","os.listdir('./')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xv0jdqtZgZ7N","executionInfo":{"status":"ok","timestamp":1710675835132,"user_tz":0,"elapsed":2851,"user":{"displayName":"Leonardo Guerra","userId":"12627539917234635942"}},"outputId":"c1d57f6a-5c9b-46d5-d109-16c3090174ad"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n","/content/gdrive/MyDrive\n"]},{"output_type":"execute_result","data":{"text/plain":["['sentiment_dataset.csv',\n"," 'RL_agent_nb.ipynb',\n"," 'Sentiment_Dset.csv',\n"," 'bert_language_model_with_sequence_classification.ipynb',\n"," 'model_without_language_model.ckpt',\n"," 'Creare presentazioni memorabili.gslides',\n"," 'TrainBertModel.ipynb']"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"l1VYM3vZJoeo","executionInfo":{"status":"ok","timestamp":1710675841187,"user_tz":0,"elapsed":6057,"user":{"displayName":"Leonardo Guerra","userId":"12627539917234635942"}}},"outputs":[],"source":["# Imports\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer\n","import torch\n","from tqdm import  tqdm_notebook\n","from tqdm import tqdm\n","from torch.optim import AdamW\n","from torch.nn import CrossEntropyLoss\n","from torch.optim import *\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import BertForSequenceClassification\n","\n","\n","\n","## Set GPU device if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":["# Load the dataset\n","dataset_name = 'sentiment_dataset.csv'\n","file_path = \"./\" + dataset_name\n","directory_path = \"./\"\n","df = pd.read_csv(file_path, delimiter=\",\")\n","\n","# Split the dataset into training and validation sets\n","train_df, val_df = train_test_split(df, test_size=0.2)\n","\n","## DATA CLEAN -> LOWERCASE, PUNCTUATION, REMOVE STOPWORDS\n","\n","\n","## OBTAIN MAX LENGTH OF TOKENIZED DSET"],"metadata":{"id":"6wDIyL6eLXud","executionInfo":{"status":"ok","timestamp":1710675916071,"user_tz":0,"elapsed":435,"user":{"displayName":"Leonardo Guerra","userId":"12627539917234635942"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class NLPDataset(Dataset):\n","    def __init__(self, phrases, labels, tokenizer, max_len):\n","        self.phrases = phrases\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.phrases)\n","\n","    def __getitem__(self, item):\n","        phrase = str(self.phrases[item])\n","        label = self.labels[item]\n","\n","        encoding = self.tokenizer.encode_plus(\n","            phrase,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            truncation=True,\n","        )\n","\n","        return {\n","            'phrase_text': phrase,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }"],"metadata":{"id":"H2Xt6-IrNcdD","executionInfo":{"status":"ok","timestamp":1710675916071,"user_tz":0,"elapsed":2,"user":{"displayName":"Leonardo Guerra","userId":"12627539917234635942"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Initialize tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Create datasets\n","max_len = 258\n","train_dataset = NLPDataset(train_df['phrase'].to_numpy(), train_df['risk_level'].to_numpy(), tokenizer, max_len)\n","val_dataset = NLPDataset(val_df['phrase'].to_numpy(), val_df['risk_level'].to_numpy(), tokenizer, max_len)\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=16)\n"],"metadata":{"id":"qJD-TGgVNish","executionInfo":{"status":"ok","timestamp":1710675916693,"user_tz":0,"elapsed":624,"user":{"displayName":"Leonardo Guerra","userId":"12627539917234635942"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["next(iter(train_loader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lapdmkoxkCS7","executionInfo":{"status":"ok","timestamp":1710675916693,"user_tz":0,"elapsed":4,"user":{"displayName":"Leonardo Guerra","userId":"12627539917234635942"}},"outputId":"762f7378-1c52-4c0c-c3e7-ae1deb015527"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'phrase_text': ['In pursuit of low-risk investments with predictable returns within a medium timeframe, balancing patience and progress.',\n","  'Conservatively approaching high-growth ventures with potential for significant returns over the long haul',\n","  \"I'm looking for low-risk investments with predictable returns in the short term\",\n","  'Committed to identifying stable, low-volatility assets for consistent gains regardless of time horizon',\n","  'In pursuit of low-risk investments with predictable returns in the short term',\n","  'Broadening horizons with stable, low-volatility assets for consistent gains in the short term, aiming for immediate profits.',\n","  'Committed to identifying in high-risk, high-reward investments in the short term',\n","  \"I'm looking for in high-risk, high-reward investments and am looking at the medium term\",\n","  \"I'm looking for moderately aggressive investments for balanced growth within a medium timeframe\",\n","  'Optimistically engaging in safe investment options can invest for medium to long term',\n","  'Aggressively targeting safe investment options regardless of time horizon',\n","  'Actively seeking out stable, low-volatility assets for consistent gains over the long haul, focusing on future security.',\n","  'Looking to diversify with high-growth ventures with potential for significant returns over the long haul',\n","  \"I'm interested in moderately aggressive investments for balanced growth regardless of time horizon\",\n","  'Seeking to enhance quick profits and am looking at the medium term',\n","  'Cautiously exploring stable, low-volatility assets for consistent gains within a medium timeframe'],\n"," 'input_ids': tensor([[  101,  1999,  8463,  ...,     0,     0,     0],\n","         [  101,  4603,  2135,  ...,     0,     0,     0],\n","         [  101,  1045,  1005,  ...,     0,     0,     0],\n","         ...,\n","         [  101,  1045,  1005,  ...,     0,     0,     0],\n","         [  101,  6224,  2000,  ...,     0,     0,     0],\n","         [  101, 15151, 11131,  ...,     0,     0,     0]]),\n"," 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         ...,\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]]),\n"," 'labels': tensor([0, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 2, 1, 2, 0])}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Training Parameters\n","lr = 2e-5\n","max_grad_norm = 1.0\n","num_total_steps = 1000\n","num_warmup_steps = 100\n","warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  # 0.1\n","\n","\n","# Fetch Model\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=3)\n","\n","optimizer = AdamW(model.parameters(), lr=lr)\n","loss_fn = CrossEntropyLoss().to(device)\n","\n","### In PyTorch-Transformers, optimizer and schedules are splitted and instantiated like this:\n","optimizer = AdamW(model.parameters(), lr=lr)  # To reproduce BertAdam specific behavior set correct_bias=False\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps = -1)  #"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["b639c6cc109d417b818f222e3edad8e6","2f1cd87081da40e5906c4271040a516e","471ad496a0654901a757836c4449b55e","39fb9f82cc974d7a8a6581db06c7df64","7b038f8dbe52460b900b25a84714fdf0","2970f890a6a849f5a6654254aff28476","43aea3a735624ef3ab9914ec68aad219","916115ac1ade44658cf6c50b6df4112a","197119cc1f864a89bb170d465b86df32","501572c52e83428cb3a0f939e5dc9825","799ba14b588349b9ac63ccfe40c9a957"]},"id":"VrGMBHOJKS5t","executionInfo":{"status":"ok","timestamp":1710675921949,"user_tz":0,"elapsed":5258,"user":{"displayName":"Leonardo Guerra","userId":"12627539917234635942"}},"outputId":"d54645a8-1319-4927-e8fd-ff6d8492b3b8"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b639c6cc109d417b818f222e3edad8e6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["model.to(device)\n","\n","total_step = len(train_loader)\n","\n","# Store our loss and accuracy for plotting\n","train_loss_set = []\n","\n","\n","epochs = 30\n","\n","# trange is a tqdm wrapper around the normal python range\n","for epoch in tqdm_notebook(range(epochs)):\n","\n","    # Training\n","    # Set our model to training mode (as opposed to evaluation mode)\n","    model.train()\n","\n","    # Tracking variables\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","\n","    # Train the data for one epoch\n","    for i, batch in enumerate(train_loader):\n","      # Unpack batch and move to GPU\n","      b_input_ids = batch['input_ids'].to(device)\n","      b_input_mask = batch['attention_mask'].to(device)\n","      b_labels = batch['labels'].to(device)\n","\n","      # Forward pass\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","      loss = outputs[0]\n","      train_loss_set.append(loss.item())\n","      # Backward pass\n","      loss.backward()\n","      # Update parameters and take a step using the computed gradient\n","      optimizer.step()\n","      scheduler.step()\n","      optimizer.zero_grad()\n","      if (i) % 50 == 0:\n","        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","                   .format(epoch+1, epochs, i+1, total_step, loss.item()))"],"metadata":{"id":"gM6fz2AcKe1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test the model\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for i, batch in enumerate(val_loader):\n","      # Unpack the inputs from our dataloader\n","      b_input_ids = batch['input_ids'].to(device)\n","      b_input_mask = batch['attention_mask'].to(device)\n","      b_labels = batch['labels'].to(device)\n","\n","      # Forward pass\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","      # print (outputs)\n","      prediction = torch.argmax(outputs[0],dim=1)\n","      total += b_labels.size(0)\n","      correct+=(prediction==b_labels).sum().item()"],"metadata":{"id":"MMjPOl-fMPga","executionInfo":{"status":"ok","timestamp":1710676948530,"user_tz":0,"elapsed":3145,"user":{"displayName":"Leonardo Guerra","userId":"12627539917234635942"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["print('Test Accuracy of the model on val data is: {} %'.format(100 * correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5-IGZXRwMeDg","executionInfo":{"status":"ok","timestamp":1710676948530,"user_tz":0,"elapsed":4,"user":{"displayName":"Leonardo Guerra","userId":"12627539917234635942"}},"outputId":"9bc3762b-253a-45b3-af1d-a9515a18e8e3"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy of the model on val data is: 98.56459330143541 %\n"]}]},{"cell_type":"code","source":["# Save the Model\n","torch.save(model.state_dict(), directory_path+'model_without_language_model.ckpt')"],"metadata":{"id":"itRgiMkbN11u","executionInfo":{"status":"ok","timestamp":1710676956266,"user_tz":0,"elapsed":7738,"user":{"displayName":"Leonardo Guerra","userId":"12627539917234635942"}}},"execution_count":16,"outputs":[]}]}